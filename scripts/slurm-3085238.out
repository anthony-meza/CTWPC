2023-05-09 20:52:01,766 - distributed.nanny - INFO -         Start Nanny at: 'tcp://172.16.3.103:46250'
2023-05-09 20:52:14,785 - distributed.worker - INFO -       Start worker at:   tcp://172.16.3.103:41754
2023-05-09 20:52:14,786 - distributed.worker - INFO -          Listening to:   tcp://172.16.3.103:41754
2023-05-09 20:52:14,786 - distributed.worker - INFO -           Worker name:             SLURMCluster-0
2023-05-09 20:52:14,786 - distributed.worker - INFO -          dashboard at:         172.16.3.103:38549
2023-05-09 20:52:14,786 - distributed.worker - INFO - Waiting to connect to:    tcp://172.16.3.56:33707
2023-05-09 20:52:14,786 - distributed.worker - INFO - -------------------------------------------------
2023-05-09 20:52:14,786 - distributed.worker - INFO -               Threads:                         36
2023-05-09 20:52:14,786 - distributed.worker - INFO -                Memory:                  93.13 GiB
2023-05-09 20:52:14,786 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-7796wffu
2023-05-09 20:52:14,786 - distributed.worker - INFO - -------------------------------------------------
2023-05-09 20:52:14,792 - distributed.worker - INFO -         Registered to:    tcp://172.16.3.56:33707
2023-05-09 20:52:14,792 - distributed.worker - INFO - -------------------------------------------------
2023-05-09 20:52:14,792 - distributed.core - INFO - Starting established connection to tcp://172.16.3.56:33707
2023-05-09 20:57:22,498 - distributed.core - INFO - Event loop was unresponsive in Worker for 44.55s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-05-09 20:57:29,521 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.91s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-05-09 20:57:35,943 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-05-09 20:58:51,576 - distributed.core - INFO - Event loop was unresponsive in Worker for 75.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-05-09 20:59:25,565 - distributed.core - INFO - Event loop was unresponsive in Worker for 33.99s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-05-09 20:59:30,301 - distributed.core - INFO - Event loop was unresponsive in Worker for 4.73s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
HDF5-DIAG: Error detected in HDF5 (1.14.0) thread 1:
  #000: H5D.c line 1390 in H5Dwrite(): can't synchronously write data
    major: Dataset
    minor: Write failed
  #001: H5D.c line 1333 in H5D__write_api_common(): can't write data
    major: Dataset
    minor: Write failed
  #002: H5VLcallback.c line 2282 in H5VL_dataset_write_direct(): dataset write failed
    major: Virtual Object Layer
    minor: Write failed
  #003: H5VLcallback.c line 2237 in H5VL__dataset_write(): dataset write failed
    major: Virtual Object Layer
    minor: Write failed
  #004: H5VLnative_dataset.c line 408 in H5VL__native_dataset_write(): can't write data
    major: Dataset
    minor: Write failed
  #005: H5Dio.c line 648 in H5D__write(): unable to initialize storage
    major: Dataset
    minor: Unable to initialize object
  #006: H5Dint.c line 2346 in H5D__alloc_storage(): unable to initialize dataset with fill value
    major: Dataset
    minor: Unable to initialize object
  #007: H5Dint.c line 2404 in H5D__init_storage(): unable to allocate all chunks of dataset
    major: Dataset
2023-05-09 21:01:14,953 - distributed.worker - WARNING - Compute Failed
Key:       ('truediv-store-map-783ad4f84beccc723caf6acac2e940c3', 0, 0, 0)
Function:  execute_task
args:      ((<function store_chunk at 0x2aaad7a700d0>, (subgraph_callable-6e14892f-1261-4e23-96c7-23a157329954, array([[[-1.36161701e+02, -1.37950745e+02, -1.28214036e+02, ...,
          6.24488910e+00,  5.58711757e+00,  4.99529240e+00],
        [-8.80706661e+01, -8.43133109e+01, -8.60939729e+01, ...,
          7.35443843e+00,  6.79154852e+00,  6.16086605e+00],
        [-4.37795940e+01, -5.70387685e+01, -8.78172150e+01, ...,
          8.79853651e+00,  8.26256831e+00,  7.59629683e+00],
        ...,
        [ 6.03106681e+01,  4.72372674e+01,  3.31236423e+01, ...,
          5.52745170e+02,  5.49151517e+02,  5.48007149e+02],
        [ 5.08649060e+01,  3.76229650e+01,  2.32227426e+01, ...,
          5.62677460e+02,  5.61411706e+02,  5.61965118e+02],
        [ 4.33027888e+01,  2.94064806e+01,  1.49476761e+01, ...,
          5.69473611e+02,  5.68072053e+02,  5.73951849e+02]],

       [[-1.32856515e+02, -1.32626084e+02, -1.18332481e+02, ...,
          3.38749922e+00,  2.78195309e+00,  2.25834123e+00],
  
kwargs:    {}
Exception: "RuntimeError('NetCDF: HDF error')"

HDF5-DIAG: Error detected in HDF5 (1.14.0) thread 2:
  #000: H5D.c line 1390 in H5Dwrite(): can't synchronously write data
    major: Dataset
    minor: Write failed
  #001: H5D.c line 1333 in H5D__write_api_common(): can't write data
    major: Dataset
    minor: Write failed
  #002: H5VLcallback.c line 2282 in H5VL_dataset_write_direct(): dataset write failed
    major: Virtual Object Layer
    minor: Write failed
  #003: H5VLcallback.c line 2237 in H5VL__dataset_write(): dataset write failed
    major: Virtual Object Layer
    minor: Write failed
  #004: H5VLnative_dataset.c line 408 in H5VL__native_dataset_write(): can't write data
    major: Dataset
    minor: Write failed
  #005: H5Dio.c line 648 in H5D__write(): unable to initialize storage
    major: Dataset
    minor: Unable to initialize object
  #006: H5Dint.c line 2346 in H5D__alloc_storage(): unable to initialize dataset with fill value
    major: Dataset
    minor: Unable to initialize object
  #007: H5Dint.c line 2404 in H5D__init_storage(): unable to allocate all chunks of dataset
    major: Dataset
    minor: Unable to initialize object
  #008: H5Dcontig.c line 312 in H5D__contig_fill(): unable to write fill value to dataset
    major: Dataset
    minor: Unable to initialize object
  #009: H5Dcontig.c line 958 in H5D__contig_write_one(): vector write failed
    major: Low-level I/O
    minor: Write failed
  #010: H5Dcontig.c line 1530 in H5D__contig_writevv(): can't perform vectorized sieve buffer write
    major: Dataset
    minor: Can't operate on object
  #011: H5VM.c line 1400 in H5VM_opvv(): can't perform operation
    major: Internal error (too specific to document in detail)
    minor: Can't operate on object
  #012: H5Dcontig.c line 1283 in H5D__contig_writevv_sieve_cb(): block write failed
    major: Dataset
    minor: Write failed
  #013: H5Fio.c line 190 in H5F_shared_block_write(): write through page buffer failed
    major: Low-level I/O
    minor: Write failed
  #014: H5PB.c line 1017 in H5PB_write(): write through metadata accumulator failed
    major: Page Buffering
    minor: Write failed
  #015: H5Faccum.c line 832 in H5F__accum_write(): file write failed
    major: Low-level I/O
    minor: Write failed
  #016: H5FDint.c line 306 in H5FD_write(): driver write request failed
    major: Virtual File Layer
    minor: Write failed
  #017: H5FDsec2.c line 850 in H5FD__sec2_write(): file write failed: time = Tue May  9 21:01:16 2023
, filename = '/vortexfs1/home/anthony.meza/Atmospheric Rivers and Waves/GLORYS_processed/ERA5_AnomaliesBandPass.nc', file descriptor = 29, errno = 122, error message = 'Disk quota exceeded', buf = 0x2aab4e4da010, total write size = 1048576, bytes this sub-write = 1048576, bytes actually written = 18446744073709551615, offset = 0
    major: Low-level I/O
    minor: Write failed
2023-05-09 21:01:16,336 - distributed.worker - WARNING - Compute Failed
Key:       ('truediv-store-map-783ad4f84beccc723caf6acac2e940c3', 1, 0, 0)
Function:  execute_task
args:      ((<function store_chunk at 0x2aaad7a700d0>, (subgraph_callable-6e14892f-1261-4e23-96c7-23a157329954, array([[[ 627.00247199,  629.39347372,  642.73179454, ...,
          -48.7603956 ,  -38.79889726,  -29.16906812],
        [ 613.26621419,  625.0219831 ,  665.9794945 , ...,
          -48.6541136 ,  -39.40459146,  -30.50529449],
        [ 646.90858083,  663.15058166,  677.04187629, ...,
          -45.90262483,  -37.72130679,  -30.22129423],
        ...,
        [-198.58445583, -198.997819  , -200.06194208, ...,
          346.89486532,  350.29500043,  357.1397001 ],
        [-196.64944028, -197.04012554, -198.2967176 , ...,
          345.82306633,  347.79074787,  354.38406542],
        [-195.11153914, -195.10276473, -196.41275477, ...,
          339.82986681,  342.35882902,  350.48483846]],

       [[ 597.02929774,  596.21901929,  604.98989778, ...,
         -242.08668237, -235.64730746, -227.19794198],
        [ 580.86156504,  589.08560213,  625.74697063, ...,
         -242.99809058, -23
kwargs:    {}
Exception: "RuntimeError('NetCDF: HDF error')"

HDF5-DIAG: Error detected in HDF5 (1.14.0) thread 3:
  #000: H5D.c line 1390 in H5Dwrite(): can't synchronously write data
    major: Dataset
    minor: Write failed
  #001: H5D.c line 1333 in H5D__write_api_common(): can't write data
    major: Dataset
    minor: Write failed
  #002: H5VLcallback.c line 2282 in H5VL_dataset_write_direct(): dataset write failed
    major: Virtual Object Layer
    minor: Write failed
  #003: H5VLcallback.c line 2237 in H5VL__dataset_write(): dataset write failed
    major: Virtual Object Layer
    minor: Write failed
  #004: H5VLnative_dataset.c line 408 in H5VL__native_dataset_write(): can't write data
    major: Dataset
    minor: Write failed
  #005: H5Dio.c line 648 in H5D__write(): unable to initialize storage
    major: Dataset
    minor: Unable to initialize object
  #006: H5Dint.c line 2346 in H5D__alloc_storage(): unable to initialize dataset with fill value
    major: Dataset
    minor: Unable to initialize object
  #007: H5Dint.c line 2404 in H5D__init_storage(): unable to allocate all chunks of dataset
    major: Dataset
    minor: Unable to initialize object
  #008: H5Dcontig.c line 312 in H5D__contig_fill(): unable to write fill value to dataset
    major: Dataset
    minor: Unable to initialize object
  #009: H5Dcontig.c line 958 in H5D__contig_write_one(): vector write failed
    major: Low-level I/O
    minor: Write failed
  #010: H5Dcontig.c line 1530 in H5D__contig_writevv(): can't perform vectorized sieve buffer write
    major: Dataset
    minor: Can't operate on object
  #011: H5VM.c line 1400 in H5VM_opvv(): can't perform operation
    major: Internal error (too specific to document in detail)
    minor: Can't operate on object
  #012: H5Dcontig.c line 1283 in H5D__contig_writevv_sieve_cb(): block write failed
    major: Dataset
    minor: Write failed
  #013: H5Fio.c line 190 in H5F_shared_block_write(): write through page buffer failed
    major: Low-level I/O
    minor: Write failed
  #014: H5PB.c line 1017 in H5PB_write(): write through metadata accumulator failed
    major: Page Buffering
    minor: Write failed
  #015: H5Faccum.c line 832 in H5F__accum_write(): file write failed
    major: Low-level I/O
    minor: Write failed
  #016: H5FDint.c line 306 in H5FD_write(): driver write request failed
    major: Virtual File Layer
    minor: Write failed
  #017: H5FDsec2.c line 850 in H5FD__sec2_write(): file write failed: time = Tue May  9 21:01:19 2023
, filename = '/vortexfs1/home/anthony.meza/Atmospheric Rivers and Waves/GLORYS_processed/ERA5_AnomaliesBandPass.nc', file descriptor = 29, errno = 122, error message = 'Disk quota exceeded', buf = 0x2aab4d388010, total write size = 1048576, bytes this sub-write = 1048576, bytes actually written = 18446744073709551615, offset = 0
    major: Low-level I/O
    minor: Write failed
2023-05-09 21:01:19,571 - distributed.worker - WARNING - Compute Failed
Key:       ('truediv-store-map-6ab91706af98d4d00eb7b95d8107fad9', 0, 0, 0)
Function:  execute_task
args:      ((<function store_chunk at 0x2aaad7a700d0>, (subgraph_callable-7c55d869-5aee-4ebb-944f-50bdfcd1f6f5, array([[[ 642.98961211,  661.17050777,  687.94221115, ...,
          156.32610335,  156.95900477,  157.79534669],
        [ 778.53295227,  809.23916938,  845.51494713, ...,
          160.80460126,  161.81733181,  162.71609847],
        [ 938.27867687,  950.76281888,  943.97517706, ...,
          165.24928208,  166.22002967,  167.25240509],
        ...,
        [ 666.209632  ,  662.99268552,  659.91510839, ...,
          417.45804465,  421.38707349,  430.11119971],
        [ 651.22264966,  648.49064725,  646.955574  , ...,
          388.82722643,  391.45316698,  398.78075307],
        [ 640.07031899,  638.46842272,  637.04290345, ...,
          358.47605384,  360.93103911,  362.48232415]],

       [[ 703.58625661,  723.92152727,  753.98078371, ...,
          158.52040266,  159.27945651,  160.24711375],
        [ 853.71414926,  888.06664438,  926.5317744 , ...,
          163.12582314,  16
kwargs:    {}
Exception: "RuntimeError('NetCDF: HDF error')"

HDF5-DIAG: Error detected in HDF5 (1.14.0) thread 4:
  #000: H5D.c line 1390 in H5Dwrite(): can't synchronously write data
    major: Dataset
    minor: Write failed
  #001: H5D.c line 1333 in H5D__write_api_common(): can't write data
    major: Dataset
    minor: Write failed
  #002: H5VLcallback.c line 2282 in H5VL_dataset_write_direct(): dataset write failed
    major: Virtual Object Layer
    minor: Write failed
  #003: H5VLcallback.c line 2237 in H5VL__dataset_write(): dataset write failed
    major: Virtual Object Layer
    minor: Write failed
  #004: H5VLnative_dataset.c line 408 in H5VL__native_dataset_write(): can't write data
    major: Dataset
    minor: Write failed
  #005: H5Dio.c line 739 in H5D__write(): can't write data
    major: Dataset
    minor: Write failed
  #006: H5Dcontig.c line 921 in H5D__contig_write(): contiguous write failed
    major: Dataset
    minor: Write failed
  #007: H5Dselect.c line 493 in H5D__select_write(): write error
    major: Dataspace
    minor: Write failed
  #008: H5Dselect.c line 230 in H5D__select_io(): write error
    major: Dataspace
    minor: Write failed
  #009: H5Dcontig.c line 1530 in H5D__contig_writevv(): can't perform vectorized sieve buffer write
    major: Dataset
    minor: Can't operate on object
  #010: H5VM.c line 1400 in H5VM_opvv(): can't perform operation
    major: Internal error (too specific to document in detail)
    minor: Can't operate on object
  #011: H5Dcontig.c line 1283 in H5D__contig_writevv_sieve_cb(): block write failed
    major: Dataset
    minor: Write failed
  #012: H5Fio.c line 190 in H5F_shared_block_write(): write through page buffer failed
    major: Low-level I/O
    minor: Write failed
  #013: H5PB.c line 1017 in H5PB_write(): write through metadata accumulator failed
    major: Page Buffering
    minor: Write failed
  #014: H5Faccum.c line 832 in H5F__accum_write(): file write failed
    major: Low-level I/O
    minor: Write failed
  #015: H5FDint.c line 306 in H5FD_write(): driver write request failed
    major: Virtual File Layer
    minor: Write failed
  #016: H5FDsec2.c line 850 in H5FD__sec2_write(): file write failed: time = Tue May  9 21:01:19 2023
, filename = '/vortexfs1/home/anthony.meza/Atmospheric Rivers and Waves/GLORYS_processed/ERA5_AnomaliesBandPass.nc', file descriptor = 29, errno = 122, error message = 'Disk quota exceeded', buf = 0x2aac85ad8010, total write size = 191869440, bytes this sub-write = 191869440, bytes actually written = 18446744073709551615, offset = 0
    major: Low-level I/O
    minor: Write failed
2023-05-09 21:01:19,581 - distributed.worker - WARNING - Compute Failed
Key:       ('truediv-store-map-783ad4f84beccc723caf6acac2e940c3', 2, 0, 0)
Function:  execute_task
args:      ((<function store_chunk at 0x2aaad7a700d0>, (subgraph_callable-6e14892f-1261-4e23-96c7-23a157329954, array([[[ 130.64020468,  118.96381022,  122.80664925, ...,
         -431.69606697, -418.16289063, -411.16040984],
        [ 130.53490875,  126.33157461,  125.64390853, ...,
         -461.41469384, -448.61298315, -437.40704242],
        [ 123.49145442,  123.22184372,  116.42427666, ...,
         -486.47464952, -476.45303629, -463.66466391],
        ...,
        [-425.87464572, -418.47459113, -412.76231092, ...,
          156.95935612,  154.90141245,  149.13129927],
        [-441.49203139, -434.37121684, -428.36742575, ...,
          148.51207283,  148.29998584,  143.44426949],
        [-455.53300394, -447.99915856, -441.96679761, ...,
          133.79674824,  133.75147394,  136.64659577]],

       [[  99.57247021,   86.33745572,   85.29003095, ...,
         -492.58425116, -477.60480591, -469.26158584],
        [ 103.99735187,   96.92154841,   89.95078078, ...,
         -525.9888317 , -51
kwargs:    {}
Exception: "RuntimeError('NetCDF: HDF error')"

2023-05-09 21:01:37,219 - distributed.utils_perf - INFO - full garbage collection released 0.90 GiB from 1120 reference cycles (threshold: 9.54 MiB)
HDF5-DIAG: Error detected in HDF5 (1.14.0) thread 5:
  #000: H5D.c line 1390 in H5Dwrite(): can't synchronously write data
    major: Dataset
    minor: Write failed
  #001: H5D.c line 1333 in H5D__write_api_common(): can't write data
    major: Dataset
    minor: Write failed
  #002: H5VLcallback.c line 2282 in H5VL_dataset_write_direct(): dataset write failed
    major: Virtual Object Layer
    minor: Write failed
  #003: H5VLcallback.c line 2237 in H5VL__dataset_write(): dataset write failed
    major: Virtual Object Layer
    minor: Write failed
  #004: H5VLnative_dataset.c line 408 in H5VL__native_dataset_write(): can't write data
    major: Dataset
    minor: Write failed
  #005: H5Dio.c line 648 in H5D__write(): unable to initialize storage
    major: Dataset
    minor: Unable to initialize object
  #006: H5Dint.c line 2346 in H5D__alloc_storage(): unable to initialize dataset with fill value
    major: Dataset
    minor: Unable to initialize object
  #007: H5Dint.c line 2404 in H5D__init_storage(): unable to allocate all chunks of dataset
    major: Dataset
    minor: Unable to initialize object
  #008: H5Dcontig.c line 312 in H5D__contig_fill(): unable to write fill value to dataset
    major: Dataset
    minor: Unable to initialize object
  #009: H5Dcontig.c line 958 in H5D__contig_write_one(): vector write failed
    major: Low-level I/O
    minor: Write failed
  #010: H5Dcontig.c line 1530 in H5D__contig_writevv(): can't perform vectorized sieve buffer write
    major: Dataset
    minor: Can't operate on object
  #011: H5VM.c line 1400 in H5VM_opvv(): can't perform operation
    major: Internal error (too specific to document in detail)
    minor: Can't operate on object
  #012: H5Dcontig.c line 1283 in H5D__contig_writevv_sieve_cb(): block write failed
    major: Dataset
    minor: Write failed
  #013: H5Fio.c line 190 in H5F_shared_block_write(): write through page buffer failed
    major: Low-level I/O
    minor: Write failed
  #014: H5PB.c line 1017 in H5PB_write(): write through metadata accumulator failed
    major: Page Buffering
    minor: Write failed
  #015: H5Faccum.c line 832 in H5F__accum_write(): file write failed
    major: Low-level I/O
    minor: Write failed
  #016: H5FDint.c line 306 in H5FD_write(): driver write request failed
    major: Virtual File Layer
    minor: Write failed
  #017: H5FDsec2.c line 850 in H5FD__sec2_write(): file write failed: time = Tue May  9 21:02:02 2023
, filename = '/vortexfs1/home/anthony.meza/Atmospheric Rivers and Waves/GLORYS_processed/ERA5_AnomaliesBandPass.nc', file descriptor = 9, errno = 122, error message = 'Disk quota exceeded', buf = 0x2aab4eba7010, total write size = 1048576, bytes this sub-write = 1048576, bytes actually written = 18446744073709551615, offset = 0
    major: Low-level I/O
    minor: Write failed
2023-05-09 21:02:02,577 - distributed.worker - WARNING - Compute Failed
Key:       ('truediv-store-map-c32ec72932ac661fbdf07d6eeb3ed1f0', 7, 0, 0)
Function:  execute_task
args:      ((<function store_chunk at 0x2aaad7a700d0>, (subgraph_callable-7c5f7875-ea9d-412f-a515-e4866a449583, array([[[ -23.81647252,  -25.27878937,  -27.59780562, ...,
           86.11675935,   84.86349328,   84.27940325],
        [ -21.06331256,  -22.37213697,  -21.53590204, ...,
           86.93767012,   86.21793811,   85.95093797],
        [ -25.69525251,  -22.61936496,  -13.75877197, ...,
           86.6946531 ,   86.5934469 ,   86.89463549],
        ...,
        [-245.67297133, -241.6576982 , -236.26379853, ...,
         -601.61061399, -642.82004726, -661.0257469 ],
        [-252.48570886, -248.6119046 , -243.11956158, ...,
         -570.40509387, -606.39791172, -622.37756768],
        [-258.12125572, -254.56110167, -249.11049414, ...,
         -537.42610141, -571.27322143, -579.98307366]],

       [[ -24.00274906,  -25.95919212,  -28.24565197, ...,
           97.51587465,   93.96866119,   90.37780722],
        [ -23.04696214,  -24.27177068,  -22.30951523, ...,
           97.7289861 ,   9
kwargs:    {}
Exception: "RuntimeError('NetCDF: HDF error')"

HDF5-DIAG: Error detected in HDF5 (1.14.0) thread 6:
  #000: H5D.c line 1390 in H5Dwrite(): can't synchronously write data
    major: Dataset
    minor: Write failed
  #001: H5D.c line 1333 in H5D__write_api_common(): can't write data
    major: Dataset
    minor: Write failed
  #002: H5VLcallback.c line 2282 in H5VL_dataset_write_direct(): dataset write failed
    major: Virtual Object Layer
    minor: Write failed
  #003: H5VLcallback.c line 2237 in H5VL__dataset_write(): dataset write failed
    major: Virtual Object Layer
    minor: Write failed
  #004: H5VLnative_dataset.c line 408 in H5VL__native_dataset_write(): can't write data
    major: Dataset
    minor: Write failed
  #005: H5Dio.c line 648 in H5D__write(): unable to initialize storage
    major: Dataset
    minor: Unable to initialize object
  #006: H5Dint.c line 2346 in H5D__alloc_storage(): unable to initialize dataset with fill value
    major: Dataset
    minor: Unable to initialize object
  #007: H5Dint.c line 2404 in H5D__init_storage(): unable to allocate all chunks of dataset
    major: Dataset
    minor: Unable to initialize object
  #008: H5Dcontig.c line 312 in H5D__contig_fill(): unable to write fill value to dataset
    major: Dataset
    minor: Unable to initialize object
  #009: H5Dcontig.c line 958 in H5D__contig_write_one(): vector write failed
    major: Low-level I/O
    minor: Write failed
  #010: H5Dcontig.c line 1530 in H5D__contig_writevv(): can't perform vectorized sieve buffer write
    major: Dataset
    minor: Can't operate on object
  #011: H5VM.c line 1400 in H5VM_opvv(): can't perform operation
    major: Internal error (too specific to document in detail)
    minor: Can't operate on object
  #012: H5Dcontig.c line 1283 in H5D__contig_writevv_sieve_cb(): block write failed
    major: Dataset
    minor: Write failed
  #013: H5Fio.c line 190 in H5F_shared_block_write(): write through page buffer failed
    major: Low-level I/O
    minor: Write failed
  #014: H5PB.c line 1017 in H5PB_write(): write through metadata accumulator failed
    major: Page Buffering
    minor: Write failed
  #015: H5Faccum.c line 832 in H5F__accum_write(): file write failed
    major: Low-level I/O
    minor: Write failed
  #016: H5FDint.c line 306 in H5FD_write(): driver write request failed
    major: Virtual File Layer
    minor: Write failed
  #017: H5FDsec2.c line 850 in H5FD__sec2_write(): file write failed: time = Tue May  9 21:02:05 2023
, filename = '/vortexfs1/home/anthony.meza/Atmospheric Rivers and Waves/GLORYS_processed/ERA5_AnomaliesBandPass.nc', file descriptor = 9, errno = 122, error message = 'Disk quota exceeded', buf = 0x2aab4e4da010, total write size = 1048576, bytes this sub-write = 1048576, bytes actually written = 18446744073709551615, offset = 0
    major: Low-level I/O
    minor: Write failed
2023-05-09 21:02:05,830 - distributed.worker - WARNING - Compute Failed
Key:       ('truediv-store-map-c32ec72932ac661fbdf07d6eeb3ed1f0', 14, 0, 0)
Function:  execute_task
args:      ((<function store_chunk at 0x2aaad7a700d0>, (subgraph_callable-7c5f7875-ea9d-412f-a515-e4866a449583, array([[[-4.01244803e-01, -6.55341051e+00, -2.02489070e+01, ...,
         -2.01075848e+02, -2.04482862e+02, -2.05077745e+02],
        [-4.90496673e+01, -5.85475918e+01, -6.26478391e+01, ...,
         -2.09327174e+02, -2.12530424e+02, -2.13199465e+02],
        [-8.93526961e+01, -8.40608652e+01, -6.15300740e+01, ...,
         -2.16757655e+02, -2.19521207e+02, -2.19732066e+02],
        ...,
        [-1.37240147e+02, -1.59251242e+02, -1.83761868e+02, ...,
          2.96656109e+02,  2.94834626e+02,  2.89758117e+02],
        [-1.71020957e+02, -1.92922912e+02, -2.16620689e+02, ...,
          2.99667012e+02,  2.94592397e+02,  2.86948210e+02],
        [-2.05293767e+02, -2.27697228e+02, -2.51309197e+02, ...,
          3.08232289e+02,  3.01920507e+02,  2.85262129e+02]],

       [[-1.38997327e+01, -2.05289912e+01, -3.41318822e+01, ...,
         -2.15905605e+02, -2.18489660e+02, -2.18229306e+02],
  
kwargs:    {}
Exception: "RuntimeError('NetCDF: HDF error')"

HDF5-DIAG: Error detected in HDF5 (1.14.0) thread 7:
  #000: H5D.c line 1390 in H5Dwrite(): can't synchronously write data
    major: Dataset
    minor: Write failed
  #001: H5D.c line 1333 in H5D__write_api_common(): can't write data
    major: Dataset
    minor: Write failed
  #002: H5VLcallback.c line 2282 in H5VL_dataset_write_direct(): dataset write failed
    major: Virtual Object Layer
    minor: Write failed
  #003: H5VLcallback.c line 2237 in H5VL__dataset_write(): dataset write failed
    major: Virtual Object Layer
    minor: Write failed
  #004: H5VLnative_dataset.c line 408 in H5VL__native_dataset_write(): can't write data
    major: Dataset
    minor: Write failed
  #005: H5Dio.c line 648 in H5D__write(): unable to initialize storage
    major: Dataset
    minor: Unable to initialize object
  #006: H5Dint.c line 2346 in H5D__alloc_storage(): unable to initialize dataset with fill value
    major: Dataset
    minor: Unable to initialize object
  #007: H5Dint.c line 2404 in H5D__init_storage(): unable to allocate all chunks of dataset
    major: Dataset
    minor: Unable to initialize object
  #008: H5Dcontig.c line 312 in H5D__contig_fill(): unable to write fill value to dataset
    major: Dataset
    minor: Unable to initialize object
  #009: H5Dcontig.c line 958 in H5D__contig_write_one(): vector write failed
    major: Low-level I/O
    minor: Write failed
  #010: H5Dcontig.c line 1530 in H5D__contig_writevv(): can't perform vectorized sieve buffer write
    major: Dataset
    minor: Can't operate on object
  #011: H5VM.c line 1400 in H5VM_opvv(): can't perform operation
    major: Internal error (too specific to document in detail)
    minor: Can't operate on object
  #012: H5Dcontig.c line 1283 in H5D__contig_writevv_sieve_cb(): block write failed
    major: Dataset
    minor: Write failed
  #013: H5Fio.c line 190 in H5F_shared_block_write(): write through page buffer failed
    major: Low-level I/O
    minor: Write failed
  #014: H5PB.c line 1017 in H5PB_write(): write through metadata accumulator failed
    major: Page Buffering
    minor: Write failed
  #015: H5Faccum.c line 832 in H5F__accum_write(): file write failed
    major: Low-level I/O
    minor: Write failed
  #016: H5FDint.c line 306 in H5FD_write(): driver write request failed
    major: Virtual File Layer
    minor: Write failed
  #017: H5FDsec2.c line 850 in H5FD__sec2_write(): file write failed: time = Tue May  9 21:02:11 2023
, filename = '/vortexfs1/home/anthony.meza/Atmospheric Rivers and Waves/GLORYS_processed/ERA5_AnomaliesBandPass.nc', file descriptor = 9, errno = 122, error message = 'Disk quota exceeded', buf = 0x2aab4e4da010, total write size = 1048576, bytes this sub-write = 1048576, bytes actually written = 18446744073709551615, offset = 0
    major: Low-level I/O
    minor: Write failed
2023-05-09 21:02:11,091 - distributed.worker - WARNING - Compute Failed
Key:       ('truediv-store-map-c32ec72932ac661fbdf07d6eeb3ed1f0', 27, 0, 0)
Function:  execute_task
args:      ((<function store_chunk at 0x2aaad7a700d0>, (subgraph_callable-7c5f7875-ea9d-412f-a515-e4866a449583, array([[[-563.12226425, -582.41096198, -586.70558493, ...,
          767.59656937,  779.01838597,  790.07619279],
        [-477.22817739, -483.80441832, -490.79400203, ...,
          769.28237355,  780.78105421,  791.89754163],
        [-393.84356181, -388.32024801, -418.04439996, ...,
          771.77123458,  784.67072946,  794.60218697],
        ...,
        [-319.02347634, -320.3697327 , -321.12554046, ...,
           15.19788523,   51.234236  ,   78.15830774],
        [-325.72074101, -326.96718323, -327.15199868, ...,
           10.25410223,   51.5199451 ,   78.64413506],
        [-331.35132999, -332.60473417, -332.7475838 , ...,
            6.54696494,   47.73206041,   77.17301244]],

       [[-525.70002386, -548.15216919, -557.36035834, ...,
          742.87596803,  757.73348946,  773.03776541],
        [-465.62639227, -475.85193125, -484.48805972, ...,
          732.97893754,  74
kwargs:    {}
Exception: "RuntimeError('NetCDF: HDF error')"

HDF5-DIAG: Error detected in HDF5 (1.14.0) thread 2:
  #000: H5D.c line 1390 in H5Dwrite(): can't synchronously write data
    major: Dataset
    minor: Write failed
  #001: H5D.c line 1333 in H5D__write_api_common(): can't write data
    major: Dataset
    minor: Write failed
  #002: H5VLcallback.c line 2282 in H5VL_dataset_write_direct(): dataset write failed
    major: Virtual Object Layer
    minor: Write failed
  #003: H5VLcallback.c line 2237 in H5VL__dataset_write(): dataset write failed
    major: Virtual Object Layer
    minor: Write failed
  #004: H5VLnative_dataset.c line 408 in H5VL__native_dataset_write(): can't write data
    major: Dataset
    minor: Write failed
  #005: H5Dio.c line 739 in H5D__write(): can't write data
    major: Dataset
    minor: Write failed
  #006: H5Dcontig.c line 921 in H5D__contig_write(): contiguous write failed
    major: Dataset
    minor: Write failed
  #007: H5Dselect.c line 493 in H5D__select_write(): write error
    major: Dataspace
    minor: Write failed
  #008: H5Dselect.c line 230 in H5D__select_io(): write error
    major: Dataspace
    minor: Write failed
  #009: H5Dcontig.c line 1530 in H5D__contig_writevv(): can't perform vectorized sieve buffer write
    major: Dataset
    minor: Can't operate on object
  #010: H5VM.c line 1400 in H5VM_opvv(): can't perform operation
    major: Internal error (too specific to document in detail)
    minor: Can't operate on object
  #011: H5Dcontig.c line 1283 in H5D__contig_writevv_sieve_cb(): block write failed
    major: Dataset
    minor: Write failed
  #012: H5Fio.c line 190 in H5F_shared_block_write(): write through page buffer failed
    major: Low-level I/O
    minor: Write failed
  #013: H5PB.c line 1017 in H5PB_write(): write through metadata accumulator failed
    major: Page Buffering
    minor: Write failed
  #014: H5Faccum.c line 832 in H5F__accum_write(): file write failed
    major: Low-level I/O
    minor: Write failed
  #015: H5FDint.c line 306 in H5FD_write(): driver write request failed
    major: Virtual File Layer
    minor: Write failed
  #016: H5FDsec2.c line 850 in H5FD__sec2_write(): file write failed: time = Tue May  9 21:02:16 2023
, filename = '/vortexfs1/home/anthony.meza/Atmospheric Rivers and Waves/GLORYS_processed/ERA5_AnomaliesBandPass.nc', file descriptor = 9, errno = 122, error message = 'Disk quota exceeded', buf = 0x2ab0db71a010, total write size = 191269848, bytes this sub-write = 191269848, bytes actually written = 18446744073709551615, offset = 0
    major: Low-level I/O
    minor: Write failed
2023-05-09 21:02:16,601 - distributed.worker - WARNING - Compute Failed
Key:       ('truediv-store-map-c32ec72932ac661fbdf07d6eeb3ed1f0', 26, 0, 0)
Function:  execute_task
args:      ((<function store_chunk at 0x2aaad7a700d0>, (subgraph_callable-7c5f7875-ea9d-412f-a515-e4866a449583, array([[[-5.21136520e+02, -5.38601210e+02, -5.61742449e+02, ...,
         -4.72210858e+02, -4.71835434e+02, -4.71354576e+02],
        [-5.23989184e+02, -5.50545886e+02, -5.97332865e+02, ...,
         -4.75371778e+02, -4.73774472e+02, -4.73135228e+02],
        [-5.49784538e+02, -5.89200132e+02, -6.34002991e+02, ...,
         -4.83941680e+02, -4.80112792e+02, -4.76872566e+02],
        ...,
        [ 3.37322775e+02,  3.29901912e+02,  3.22357397e+02, ...,
         -8.21882208e+01, -1.03387799e+02, -1.30765838e+02],
        [ 3.30082642e+02,  3.23357404e+02,  3.15202998e+02, ...,
         -8.78667949e+01, -1.12407278e+02, -1.39218256e+02],
        [ 3.17907549e+02,  3.14374823e+02,  3.06725196e+02, ...,
         -9.17376688e+01, -1.16513653e+02, -1.39471019e+02]],

       [[-3.36151917e+02, -3.51963250e+02, -3.71509939e+02, ...,
         -4.72733008e+02, -4.73970153e+02, -4.75342433e+02],
  
kwargs:    {}
Exception: "RuntimeError('NetCDF: HDF error')"

slurmstepd: error: *** JOB 3085238 ON pn053 CANCELLED AT 2023-05-09T21:03:41 ***

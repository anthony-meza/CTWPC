2023-05-03 13:33:30,212 - distributed.nanny - INFO -         Start Nanny at: 'tcp://172.16.3.166:36867'
2023-05-03 13:33:32,161 - distributed.worker - INFO -       Start worker at:   tcp://172.16.3.166:38605
2023-05-03 13:33:32,161 - distributed.worker - INFO -          Listening to:   tcp://172.16.3.166:38605
2023-05-03 13:33:32,161 - distributed.worker - INFO -           Worker name:             SLURMCluster-4
2023-05-03 13:33:32,161 - distributed.worker - INFO -          dashboard at:         172.16.3.166:44743
2023-05-03 13:33:32,161 - distributed.worker - INFO - Waiting to connect to:    tcp://172.16.3.87:37981
2023-05-03 13:33:32,161 - distributed.worker - INFO - -------------------------------------------------
2023-05-03 13:33:32,161 - distributed.worker - INFO -               Threads:                         36
2023-05-03 13:33:32,161 - distributed.worker - INFO -                Memory:                 178.81 GiB
2023-05-03 13:33:32,161 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-m2y3m2ei
2023-05-03 13:33:32,161 - distributed.worker - INFO - -------------------------------------------------
2023-05-03 13:33:32,167 - distributed.worker - INFO -         Registered to:    tcp://172.16.3.87:37981
2023-05-03 13:33:32,167 - distributed.worker - INFO - -------------------------------------------------
2023-05-03 13:33:32,167 - distributed.core - INFO - Starting established connection to tcp://172.16.3.87:37981
/vortexfs1/home/anthony.meza/mambaforge/envs/atm_rivers/lib/python3.10/site-packages/scipy/io/_netcdf.py:305: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)
  warnings.warn((
HDF5-DIAG: Error detected in HDF5 (1.14.0) thread 1:
  #000: H5D.c line 1390 in H5Dwrite(): can't synchronously write data
    major: Dataset
    minor: Write failed
  #001: H5D.c line 1333 in H5D__write_api_common(): can't write data
    major: Dataset
    minor: Write failed
  #002: H5VLcallback.c line 2282 in H5VL_dataset_write_direct(): dataset write failed
    major: Virtual Object Layer
    minor: Write failed
  #003: H5VLcallback.c line 2237 in H5VL__dataset_write(): dataset write failed
    major: Virtual Object Layer
    minor: Write failed
  #004: H5VLnative_dataset.c line 408 in H5VL__native_dataset_write(): can't write data
    major: Dataset
    minor: Write failed
  #005: H5Dio.c line 648 in H5D__write(): unable to initialize storage
    major: Dataset
    minor: Unable to initialize object
  #006: H5Dint.c line 2346 in H5D__alloc_storage(): unable to initialize dataset with fill value
    major: Dataset
    minor: Unable to initialize object
  #007: H5Dint.c line 2404 in H5D__init_storage(): unable to allocate all chunks of dataset
    major: Dataset
    minor: Unable to initialize object
  #008: H5Dcontig.c line 312 in H5D__contig_fill(): unable to write fill value to dataset
    major: Dataset
    minor: Unable to initialize object
  #009: H5Dcontig.c line 958 in H5D__contig_write_one(): vector write failed
    major: Low-level I/O
    minor: Write failed
  #010: H5Dcontig.c line 1530 in H5D__contig_writevv(): can't perform vectorized sieve buffer write
    major: Dataset
    minor: Can't operate on object
  #011: H5VM.c line 1400 in H5VM_opvv(): can't perform operation
    major: Internal error (too specific to document in detail)
    minor: Can't operate on object
  #012: H5Dcontig.c line 1283 in H5D__contig_writevv_sieve_cb(): block write failed
    major: Dataset
    minor: Write failed
  #013: H5Fio.c line 190 in H5F_shared_block_write(): write through page buffer failed
    major: Low-level I/O
    minor: Write failed
    major: Page Buffering
    minor: Write failed
thread 2:

2023-05-04 16:55:23,230 - distributed.nanny - INFO -         Start Nanny at: 'tcp://172.16.3.102:39384'
2023-05-04 16:55:26,864 - distributed.worker - INFO -       Start worker at:   tcp://172.16.3.102:45592
2023-05-04 16:55:26,865 - distributed.worker - INFO -          Listening to:   tcp://172.16.3.102:45592
2023-05-04 16:55:26,866 - distributed.worker - INFO -           Worker name:             SLURMCluster-4
2023-05-04 16:55:26,866 - distributed.worker - INFO -          dashboard at:         172.16.3.102:36188
2023-05-04 16:55:26,866 - distributed.worker - INFO - Waiting to connect to:   tcp://172.16.3.106:34539
2023-05-04 16:55:26,866 - distributed.worker - INFO - -------------------------------------------------
2023-05-04 16:55:26,866 - distributed.worker - INFO -               Threads:                         36
2023-05-04 16:55:26,866 - distributed.worker - INFO -                Memory:                  46.57 GiB
2023-05-04 16:55:26,866 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-x3p26p0u
2023-05-04 16:55:26,866 - distributed.worker - INFO - -------------------------------------------------
2023-05-04 16:55:26,873 - distributed.worker - INFO -         Registered to:   tcp://172.16.3.106:34539
2023-05-04 16:55:26,873 - distributed.worker - INFO - -------------------------------------------------
2023-05-04 16:55:26,874 - distributed.core - INFO - Starting established connection to tcp://172.16.3.106:34539
2023-05-04 17:02:20,554 - distributed.worker - WARNING - Compute Failed
Key:       _preprocess-e31de47a-f83c-44d4-8f05-a035f655df37
Function:  _preprocess
args:      (<xarray.Dataset>
Dimensions:     (depth: 50, latitude: 745, longitude: 901)
Coordinates:
  * latitude    (latitude) float32 -2.0 -1.917 -1.833 -1.75 ... 59.83 59.92 60.0
  * longitude   (longitude) float32 -150.0 -149.9 -149.8 ... -75.17 -75.08 -75.0
  * depth       (depth) float32 0.494 1.541 2.646 ... 5.275e+03 5.728e+03
Data variables:
    mask        (depth, latitude, longitude) int8 dask.array<chunksize=(1, 745, 901), meta=np.ndarray>
    deptho      (latitude, longitude) float32 dask.array<chunksize=(745, 901), meta=np.ndarray>
    deptho_lev  (latitude, longitude) float32 dask.array<chunksize=(745, 901), meta=np.ndarray>
    CoastMask   (latitude, longitude) float32 dask.array<chunksize=(745, 901), meta=np.ndarray>
    GC_E        (latitude, longitude) float32 dask.array<chunksize=(745, 901), meta=np.ndarray>
    GC_W        (latitude, longitude) float32 dask.array<chunksize=(745, 901), meta=np.ndarray>
    GC_C        (latitude, longitude) float32 dask.array<chunksize=(745, 90
kwargs:    {}
Exception: 'KeyError("\'time\' is not a valid dimension or coordinate")'

/vortexfs1/home/anthony.meza/mambaforge/envs/atm_rivers/lib/python3.10/site-packages/dask/core.py:119: RuntimeWarning: invalid value encountered in divide
  return func(*(_execute_task(a, cache) for a in args))
2023-05-04 17:04:07,880 - distributed.utils_perf - INFO - full garbage collection released 0.91 GiB from 251 reference cycles (threshold: 9.54 MiB)
2023-05-04 17:14:06,432 - distributed.utils_perf - INFO - full garbage collection released 58.91 MiB from 300 reference cycles (threshold: 9.54 MiB)
2023-05-04 17:17:40,501 - distributed.utils_perf - INFO - full garbage collection released 339.22 MiB from 243 reference cycles (threshold: 9.54 MiB)
2023-05-04 17:28:16,357 - distributed.utils_perf - INFO - full garbage collection released 1.78 GiB from 552 reference cycles (threshold: 9.54 MiB)
2023-05-04 17:30:37,177 - distributed.utils_perf - INFO - full garbage collection released 130.15 MiB from 363 reference cycles (threshold: 9.54 MiB)
2023-05-04 17:33:01,647 - distributed.utils_perf - INFO - full garbage collection released 168.86 MiB from 420 reference cycles (threshold: 9.54 MiB)
2023-05-04 17:35:47,212 - distributed.utils_perf - INFO - full garbage collection released 283.97 MiB from 366 reference cycles (threshold: 9.54 MiB)
2023-05-04 17:41:32,523 - distributed.utils_perf - INFO - full garbage collection released 664.55 MiB from 547 reference cycles (threshold: 9.54 MiB)
2023-05-04 18:17:14,011 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/vortexfs1/home/anthony.meza/mambaforge/envs/atm_rivers/lib/python3.10/site-packages/tornado/iostream.py", line 861, in _read_to_buffer
    bytes_read = self.read_from_fd(buf)
  File "/vortexfs1/home/anthony.meza/mambaforge/envs/atm_rivers/lib/python3.10/site-packages/tornado/iostream.py", line 1116, in read_from_fd
    return self.socket.recv_into(buf, len(buf))
ConnectionResetError: [Errno 104] Connection reset by peer

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/vortexfs1/home/anthony.meza/mambaforge/envs/atm_rivers/lib/python3.10/site-packages/distributed/worker.py", line 1237, in heartbeat
    response = await retry_operation(
  File "/vortexfs1/home/anthony.meza/mambaforge/envs/atm_rivers/lib/python3.10/site-packages/distributed/utils_comm.py", line 434, in retry_operation
    return await retry(
  File "/vortexfs1/home/anthony.meza/mambaforge/envs/atm_rivers/lib/python3.10/site-packages/distributed/utils_comm.py", line 413, in retry
    return await coro()
  File "/vortexfs1/home/anthony.meza/mambaforge/envs/atm_rivers/lib/python3.10/site-packages/distributed/core.py", line 1269, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/vortexfs1/home/anthony.meza/mambaforge/envs/atm_rivers/lib/python3.10/site-packages/distributed/core.py", line 1028, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/vortexfs1/home/anthony.meza/mambaforge/envs/atm_rivers/lib/python3.10/site-packages/distributed/comm/tcp.py", line 241, in read
    convert_stream_closed_error(self, e)
  File "/vortexfs1/home/anthony.meza/mambaforge/envs/atm_rivers/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) ConnectionPool.heartbeat_worker local=tcp://172.16.3.102:54011 remote=tcp://172.16.3.106:34539>: ConnectionResetError: [Errno 104] Connection reset by peer
2023-05-04 18:17:14,079 - distributed.core - INFO - Connection to tcp://172.16.3.106:34539 has been closed.
2023-05-04 18:17:14,079 - distributed.worker - INFO - Stopping worker at tcp://172.16.3.102:45592. Reason: worker-handle-scheduler-connection-broken
2023-05-04 18:17:14,082 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://172.16.3.102:39384'. Reason: worker-handle-scheduler-connection-broken
2023-05-04 18:17:14,086 - distributed.nanny - INFO - Worker closed
2023-05-04 18:17:17,096 - distributed.nanny - INFO - Closing Nanny at 'tcp://172.16.3.102:39384'. Reason: nanny-close-gracefully
2023-05-04 18:17:17,097 - distributed.dask_worker - INFO - End worker

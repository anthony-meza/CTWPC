{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0f0f1a51-ad0f-4694-9e19-44016f728430",
   "metadata": {},
   "source": [
    "#### This notebook takes raw ERA5 (pressure-coordinate) data and performs the following operations using Dask: \n",
    "1. Concatenate the disjointed ERA5 files over some region \n",
    "2. Saves the concatenated data \n",
    "3. Uses concatenated data to compute a daily climatology \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2669743-66c8-426d-a957-9cfd6d15d446",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, gc; from os.path import exists\n",
    "os.chdir('/vortexfs1/home/anthony.meza/CTWPC/scripts')\n",
    "main_dir = \"/vortexfs1/home/anthony.meza/CTWPC\"\n",
    "plotsdir = lambda x=\"\": main_dir + \"/plots/\" + x\n",
    "GLORYS_dir = lambda x=\"\": main_dir + \"/GLORYS_data\" + x\n",
    "GLORYS_data_dir = lambda x=\"\": main_dir + \"/GLORYS_processed/\" + x\n",
    "ERA5_data_dir = lambda x=\"\": main_dir + \"/ERA5_data/\" + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6be779b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from help_funcs import * \n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import netCDF4 as nc\n",
    "from pathlib import Path\n",
    "from natsort import natsorted\n",
    "import matplotlib.pyplot as plt\n",
    "import dask_labextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e992700-63e1-45fc-9406-7c8e0dd42056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/usr/bin/env bash\n",
      "\n",
      "#SBATCH -J dask-worker\n",
      "#SBATCH -p compute\n",
      "#SBATCH -n 1\n",
      "#SBATCH --cpus-per-task=30\n",
      "#SBATCH --mem=140G\n",
      "#SBATCH -t 02:00:00\n",
      "\n",
      "/vortexfs1/home/anthony.meza/mambaforge/envs/atm_rivers/bin/python -m distributed.cli.dask_worker tcp://172.16.3.56:37106 --nthreads 30 --memory-limit 139.70GiB --name dummy-name --nanny --death-timeout 60 --interface ib0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from dask_jobqueue import SLURMCluster  # setup dask cluster \n",
    "cluster = SLURMCluster(\n",
    "    cores=36,\n",
    "    processes=1,\n",
    "    memory='150GB',\n",
    "    walltime='02:00:00',\n",
    "    queue='compute',\n",
    "    interface='ib0')\n",
    "print(cluster.job_script())\n",
    "cluster.scale(jobs=14)\n",
    "from dask.distributed import Client\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae2eddc9-6ca8-40d8-b6a0-db9bc7c3c43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search for the correct files\n",
    "results_era5 = natsorted(str(result) for result in list(Path(ERA5_data_dir()).rglob(\"*.[nN][cC]\")))\n",
    "results_era5_filtered = []\n",
    "for result in results_era5:\n",
    "    if len(result) < 81:\n",
    "        results_era5_filtered = results_era5_filtered + [result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c76e790-c768-40a6-806e-65897d85eb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract IVT components\n",
    "def _preprocess_ERA5(ds):\n",
    "    return ds[[\"p71.162\", \"p72.162\"]].sel(latitude = slice(60, -2)).sel(longitude = slice(-150, -75)).resample(time=\"1D\").mean().sel(time = slice(\"1992\", None))\n",
    "\n",
    "ds = xr.open_mfdataset(\n",
    "        results_era5_filtered,\n",
    "        data_vars=\"minimal\",\n",
    "        coords=\"minimal\",\n",
    "        compat=\"override\",\n",
    "        preprocess=_preprocess_ERA5,\n",
    "        parallel=True, engine = \"netcdf4\", \n",
    "        chunks={\"latitude\":-1, \"longitude\":-1, \"time\":-1})\n",
    "\n",
    "#save the dataset before processing \n",
    "ds.to_netcdf(GLORYS_data_dir(\"ERA5_WaterVars_NE_PAC_daily.nc\"),\n",
    "             mode = \"w\", format = \"NETCDF4\", \n",
    "             engine = \"netcdf4\", compute = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26788a56-1c1c-436a-9212-16fa6e36196d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reopen daily fields that have been saved in a nicer format and save the anomalies\n",
    "gc.collect()\n",
    "era5_daily = xr.open_mfdataset(GLORYS_data_dir(\"ERA5_WaterVars_NE_PAC_daily.nc\"), \n",
    "                                data_vars=\"minimal\",\n",
    "                                coords=\"minimal\",\n",
    "                                compat=\"override\",\n",
    "                                parallel=True,\n",
    "                                chunks={\"longitude\": -1, \"latitude\":-1, \"time\":320},\n",
    "                                engine=\"netcdf4\")\n",
    "era5_daily = era5_daily.convert_calendar('noleap') #remove leap years from operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d171713-e33b-447f-b4b3-a384e43240ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "era5_climatology = era5_daily.groupby(\"time.dayofyear\").mean(\"time\")\n",
    "era5_climatology.to_netcdf(ERA5_data_dir(\"ERA5_WaterVars_Daily_Climatology.nc\"),\n",
    "             mode = \"w\", format = \"NETCDF4\", \n",
    "             engine = \"netcdf4\", compute = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Atmospheric Rivers)",
   "language": "python",
   "name": "atm_rivers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

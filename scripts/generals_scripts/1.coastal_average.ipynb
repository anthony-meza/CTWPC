{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0f0f1a51-ad0f-4694-9e19-44016f728430",
   "metadata": {},
   "source": [
    "### The purpose of this notebook to is to recreate the regress the SSH in GLORYS onto the CWI developed in Amaya et al. (2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2669743-66c8-426d-a957-9cfd6d15d446",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os; from os.path import exists\n",
    "os.chdir('/vortexfs1/home/anthony.meza/Atmospheric Rivers and Waves/scripts')\n",
    "plotsdir = lambda x=\"\": \"/vortexfs1/home/anthony.meza/Atmospheric Rivers and Waves/plots/\" + x\n",
    "GLORYS_dir = lambda x=\"\": \"/vortexfs1/home/anthony.meza/GLORYS_data\" + x\n",
    "GLORYS_data_dir = lambda x=\"\": \"/vortexfs1/home/anthony.meza/Atmospheric Rivers and Waves/GLORYS_processed/\" + x\n",
    "ERA5_data_dir = lambda x=\"\": \"/vortexfs1/home/anthony.meza/Atmospheric Rivers and Waves/ERA5_data/\" + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6be779b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from help_funcs import * \n",
    "import gsw, gc , os, multiprocessing, importlib\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import xarray as xr\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import cmocean.cm as cm\n",
    "import netCDF4 as nc\n",
    "from pathlib import Path\n",
    "from natsort import natsorted\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Pool\n",
    "import dask_labextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40c7ad7e-6bff-4f67-8c8d-787da8359845",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from natsort import natsorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa0ec27e-8903-466e-8b44-50eef11bd7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_seasonal(ds):\n",
    "    climatology = ds.groupby(\"time.month\").mean(\"time\")\n",
    "    anomalies = ds.groupby(\"time.month\") - climatology\n",
    "    return anomalies\n",
    "def remove_daily_climatology(ds):\n",
    "    climatology = ds.groupby(\"time.dayofyear\").mean(\"time\")\n",
    "    anomalies = ds.groupby(\"time.dayofyear\") - climatology\n",
    "    return anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e992700-63e1-45fc-9406-7c8e0dd42056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/usr/bin/env bash\n",
      "\n",
      "#SBATCH -J dask-worker\n",
      "#SBATCH -p compute\n",
      "#SBATCH -n 1\n",
      "#SBATCH --cpus-per-task=36\n",
      "#SBATCH --mem=94G\n",
      "#SBATCH -t 02:00:00\n",
      "\n",
      "/vortexfs1/home/anthony.meza/mambaforge/envs/atm_rivers/bin/python -m distributed.cli.dask_worker tcp://172.16.3.56:34946 --nthreads 36 --memory-limit 93.13GiB --name dummy-name --nanny --death-timeout 60 --interface ib0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from dask_jobqueue import SLURMCluster  # setup dask cluster \n",
    "cluster = SLURMCluster(\n",
    "    cores=36,\n",
    "    processes=1,\n",
    "    memory='100GB',\n",
    "    walltime='02:00:00',\n",
    "    queue='compute',\n",
    "    interface='ib0')\n",
    "print(cluster.job_script())\n",
    "cluster.scale(jobs=8)\n",
    "from dask.distributed import Client\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "71b57fa1-07e6-4242-b5ef-c7493439980c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Reading in the GLORYS and ERA5 data files. Files have been preprocessed and combined in order to take advantage of the **dask** feature of xarray. We also remove their seasonal cliamtologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c83d8ed1-978e-4e15-9fdb-470ec4001159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 270 ms, sys: 55.1 ms, total: 325 ms\n",
      "Wall time: 3.09 s\n"
     ]
    }
   ],
   "source": [
    "chunk_size = -1\n",
    "def _preprocess(ds):\n",
    "    return ds.sel(latitude = slice(-2, 60), longitude = slice(-150, -75))\n",
    "ds = xr.open_mfdataset(\n",
    "        GLORYS_data_dir(\"GLORYS_NE_PAC.nc\"),\n",
    "        data_vars=\"minimal\",\n",
    "        coords=\"minimal\",\n",
    "        compat=\"override\",\n",
    "        preprocess=_preprocess,\n",
    "        parallel=True,\n",
    "        chunks={\"time\":120, \"latitude\":chunk_size, \"longitude\":chunk_size, \"depth\":1},\n",
    "        engine=\"netcdf4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a15638d-4462-4397-806f-d51bb422b723",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bathy_preprocess(ds):\n",
    "    return ds.sel(depth = ds.depth.values, method = \"nearest\").sel(latitude = slice(-2, 60), \n",
    "                        longitude = slice(-150, -75))\n",
    "\n",
    "bathy_ds = xr.open_mfdataset(GLORYS_data_dir(\"CaliforniaCoastalMask.nc\"), \n",
    "                             preprocess=_preprocess,\n",
    "                             parallel=True, \n",
    "                            chunks={\"latitude\":chunk_size, \"longitude\":chunk_size, \"depth\":1},\n",
    "                            engine=\"netcdf4\")\n",
    "weighted_mask_ds = xr.open_mfdataset(GLORYS_data_dir(\"CaliforniaCoastalMaskWeighted.nc\"), \n",
    "                             preprocess=_preprocess,\n",
    "                             parallel=True, \n",
    "                            chunks={\"latitude\":chunk_size, \"longitude\":chunk_size, \"depth\":1},\n",
    "                            engine=\"netcdf4\")\n",
    "LON, LAT = np.meshgrid(ds.longitude.values, ds.latitude.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25d1c04f-bb0e-42ec-963e-ebf23b95e4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SW\n",
      "GC_C\n",
      "SW\n",
      "GC_C\n"
     ]
    }
   ],
   "source": [
    "#approximates the average latitude and longitude of each coastal point\n",
    "latitudes = zonal_average_coastline(LAT, weighted_mask_ds)\n",
    "longitudes = zonal_average_coastline(LON, weighted_mask_ds)\n",
    "list_lats = stitch_zonal_average(latitudes)\n",
    "list_lons = stitch_zonal_average(longitudes)\n",
    "\n",
    "#plots the average latitude and longitude\n",
    "dists = []\n",
    "for i in range(0, len(list_lats)-1):\n",
    "    a = haversine(list_lons[i], list_lats[i], list_lons[i+1], list_lats[i+1])\n",
    "    dists = np.concatenate([dists, [a]])\n",
    "plt.scatter(list_lons, list_lats, s = 0.1)\n",
    "\n",
    "#computees cumulative distance from start to end of the \"shelf\"\n",
    "cum_distance = np.concatenate([[0.0], np.cumsum(dists)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06da9422-6c96-48f5-894c-1c0e1acb62c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EQ\n",
      "COL\n",
      "SW\n",
      "GC_E\n",
      "GC_C\n",
      "GC_W\n",
      "NW\n",
      "CPU times: user 1min 35s, sys: 8.23 s, total: 1min 43s\n",
      "Wall time: 19min 28s\n"
     ]
    }
   ],
   "source": [
    "#computes the averages of geophysical variables within the shelf\n",
    "zos_dict = zonal_average_coastline(ds[\"zos\"], weighted_mask_ds)\n",
    "theta_dict = zonal_average_coastline_depth(ds[\"thetao\"], weighted_mask_ds, bathy_ds.wet_mask)\n",
    "for key in [\"EQ\", \"COL\", \"SW\", \"GC_E\", \"GC_C\", \"GC_W\", \"NW\"]:\n",
    "    print(key)\n",
    "    zos_dict[key] = zos_dict[key].compute()\n",
    "    theta_dict[key] = theta_dict[key].compute()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99565375-bacb-4e9e-950f-1d69edd5448b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_stich_zonal_average = lambda ds=stich_zonal_average_xr(ds, longitudes, latitudes, cum_distance)\n",
    "\n",
    "#concatenates the averages into one dataset \n",
    "theato_coast = xr.concat(xr_stich_zonal_average(theta_dict), dim = \"distance\"); theato_coast.name = \"thetao\"\n",
    "zos_coast = xr.concat(xr_stich_zonal_average(zos_dict), dim = \"distance\"); zos_coast.name = \"zos\"\n",
    "coast_vars = xr.merge([theato_coast, zos_coast], compat='override')\n",
    "\n",
    "#adding units\n",
    "coast_vars.distance.attrs['units'] = 'km'\n",
    "coast_vars.zos.attrs['units'] = 'm'\n",
    "coast_vars.thetao.attrs['units'] = 'deg C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de11d514-0b6b-49d5-a21e-3084eb83a76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hovmoller_ds = xr.Dataset(\n",
    "        data_vars=dict(\n",
    "        lat_path=([\"distance\"], list_lats ),\n",
    "        lon_path=([\"distance\"], list_lons)\n",
    "     ),\n",
    "     coords=dict(\n",
    "         distance=([\"distance\"], cum_distance),\n",
    "         time=ds.time.values,\n",
    "     ),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9acfee63-c3c5-40ca-94bb-a95dcfd97df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EQ\n",
      "COL\n",
      "SW\n",
      "GC_E\n",
      "GC_C\n",
      "GC_W\n",
      "NW\n"
     ]
    }
   ],
   "source": [
    "hovmoller_mask_dict = zonal_average_coastline(bathy_ds[[\"EQ\", \"COL\", \"SW\", \"GC_E\", \"GC_C\", \"GC_W\", \"NW\"]], weighted_mask_ds)\n",
    "\n",
    "for key in [\"EQ\", \"COL\", \"SW\", \"GC_E\", \"GC_C\", \"GC_W\", \"NW\"]:\n",
    "    print(key)\n",
    "    hovmoller_mask_dict[key] = hovmoller_mask_dict[key].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9193b883-25a9-4990-85b5-be52fecab237",
   "metadata": {},
   "outputs": [],
   "source": [
    "hovmoller_mask_ds =  xr.concat(xr_stich_zonal_average(hovmoller_mask_dict), dim = \"distance\")\n",
    "hovmoller_ds = xr.merge([hovmoller_ds, hovmoller_mask_ds])\n",
    "hovmoller_ds.distance.attrs['units'] = 'km'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f2545bdc-3f0b-48ad-83ff-fe48c4ec0fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "coast_vars.to_netcdf(GLORYS_data_dir(\"GLORYS_Coastal_Vars.nc\"),\n",
    "             mode = \"w\", format = \"NETCDF4\", \n",
    "             engine = \"netcdf4\", compute = True)\n",
    "hovmoller_ds.to_netcdf(GLORYS_data_dir(\"GLORYS_Coastal_Path.nc\"),\n",
    "             mode = \"w\", format = \"NETCDF4\", \n",
    "             engine = \"netcdf4\", compute = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0c7010-6583-4d54-b752-56a423de4641",
   "metadata": {},
   "outputs": [],
   "source": [
    "coast_vars.thetao.isel(depth =2).plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Atmospheric Rivers)",
   "language": "python",
   "name": "atm_rivers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

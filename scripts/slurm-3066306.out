2023-04-18 13:18:20,088 - distributed.nanny - INFO -         Start Nanny at: 'tcp://172.16.3.86:37083'
2023-04-18 13:18:20,481 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-worker-space/worker-ypjg5r04', purging
2023-04-18 13:18:21,406 - distributed.worker - INFO -       Start worker at:    tcp://172.16.3.86:43691
2023-04-18 13:18:21,407 - distributed.worker - INFO -          Listening to:    tcp://172.16.3.86:43691
2023-04-18 13:18:21,407 - distributed.worker - INFO -           Worker name:             SLURMCluster-1
2023-04-18 13:18:21,407 - distributed.worker - INFO -          dashboard at:          172.16.3.86:37725
2023-04-18 13:18:21,407 - distributed.worker - INFO - Waiting to connect to:    tcp://172.16.3.91:39395
2023-04-18 13:18:21,407 - distributed.worker - INFO - -------------------------------------------------
2023-04-18 13:18:21,407 - distributed.worker - INFO -               Threads:                         36
2023-04-18 13:18:21,407 - distributed.worker - INFO -                Memory:                 166.71 GiB
2023-04-18 13:18:21,407 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-o1364rcz
2023-04-18 13:18:21,407 - distributed.worker - INFO - -------------------------------------------------
2023-04-18 13:18:21,412 - distributed.worker - INFO -         Registered to:    tcp://172.16.3.91:39395
2023-04-18 13:18:21,412 - distributed.worker - INFO - -------------------------------------------------
2023-04-18 13:18:21,413 - distributed.core - INFO - Starting established connection to tcp://172.16.3.91:39395
2023-04-18 14:00:02,895 - distributed.core - INFO - Event loop was unresponsive in Worker for 3.54s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-04-18 15:12:18,000 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.89s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-04-18 15:12:30,529 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.48s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-04-18 15:12:42,230 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.06s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-04-18 15:12:57,829 - distributed.core - INFO - Event loop was unresponsive in Worker for 6.51s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-04-18 15:13:14,459 - distributed.core - INFO - Event loop was unresponsive in Worker for 5.83s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-04-18 15:14:02,452 - distributed.core - INFO - Event loop was unresponsive in Worker for 7.78s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
2023-04-18 15:14:06,166 - distributed.worker - ERROR - failed during get data with tcp://172.16.3.86:43691 -> tcp://172.16.3.95:42027
Traceback (most recent call last):
  File "/vortexfs1/home/anthony.meza/.conda/envs/notebook_env/lib/python3.10/site-packages/tornado/iostream.py", line 971, in _handle_write
    num_bytes = self.write_to_fd(self._write_buffer.peek(size))
  File "/vortexfs1/home/anthony.meza/.conda/envs/notebook_env/lib/python3.10/site-packages/tornado/iostream.py", line 1148, in write_to_fd
    return self.socket.send(data)  # type: ignore
BrokenPipeError: [Errno 32] Broken pipe

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/vortexfs1/home/anthony.meza/.conda/envs/notebook_env/lib/python3.10/site-packages/distributed/worker.py", line 1758, in get_data
    response = await comm.read(deserializers=serializers)
  File "/vortexfs1/home/anthony.meza/.conda/envs/notebook_env/lib/python3.10/site-packages/distributed/comm/tcp.py", line 241, in read
    convert_stream_closed_error(self, e)
  File "/vortexfs1/home/anthony.meza/.conda/envs/notebook_env/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://172.16.3.86:43691 remote=tcp://172.16.3.95:35491>: BrokenPipeError: [Errno 32] Broken pipe
2023-04-18 15:14:06,194 - distributed.core - INFO - Lost connection to 'tcp://172.16.3.95:35491'
Traceback (most recent call last):
  File "/vortexfs1/home/anthony.meza/.conda/envs/notebook_env/lib/python3.10/site-packages/tornado/iostream.py", line 971, in _handle_write
    num_bytes = self.write_to_fd(self._write_buffer.peek(size))
  File "/vortexfs1/home/anthony.meza/.conda/envs/notebook_env/lib/python3.10/site-packages/tornado/iostream.py", line 1148, in write_to_fd
    return self.socket.send(data)  # type: ignore
BrokenPipeError: [Errno 32] Broken pipe

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/vortexfs1/home/anthony.meza/.conda/envs/notebook_env/lib/python3.10/site-packages/distributed/core.py", line 771, in _handle_comm
    result = await result
  File "/vortexfs1/home/anthony.meza/.conda/envs/notebook_env/lib/python3.10/site-packages/distributed/worker.py", line 1758, in get_data
    response = await comm.read(deserializers=serializers)
  File "/vortexfs1/home/anthony.meza/.conda/envs/notebook_env/lib/python3.10/site-packages/distributed/comm/tcp.py", line 241, in read
    convert_stream_closed_error(self, e)
  File "/vortexfs1/home/anthony.meza/.conda/envs/notebook_env/lib/python3.10/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc.__class__.__name__}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://172.16.3.86:43691 remote=tcp://172.16.3.95:35491>: BrokenPipeError: [Errno 32] Broken pipe
2023-04-18 15:14:06,196 - distributed.core - INFO - Connection to tcp://172.16.3.91:39395 has been closed.
2023-04-18 15:14:06,196 - distributed.worker - INFO - Stopping worker at tcp://172.16.3.86:43691. Reason: worker-handle-scheduler-connection-broken
2023-04-18 15:14:06,201 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://172.16.3.86:37083'. Reason: worker-handle-scheduler-connection-broken
2023-04-18 15:14:06,207 - distributed.nanny - INFO - Worker closed
2023-04-18 15:14:08,209 - distributed.nanny - ERROR - Worker process died unexpectedly
2023-04-18 15:14:08,661 - distributed.nanny - INFO - Closing Nanny at 'tcp://172.16.3.86:37083'. Reason: nanny-close-gracefully
2023-04-18 15:14:08,662 - distributed.dask_worker - INFO - End worker

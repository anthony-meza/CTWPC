2023-05-03 13:33:30,208 - distributed.nanny - INFO -         Start Nanny at: 'tcp://172.16.3.62:45760'
2023-05-03 13:33:32,195 - distributed.worker - INFO -       Start worker at:    tcp://172.16.3.62:37339
2023-05-03 13:33:32,196 - distributed.worker - INFO -          Listening to:    tcp://172.16.3.62:37339
2023-05-03 13:33:32,196 - distributed.worker - INFO -           Worker name:             SLURMCluster-1
2023-05-03 13:33:32,196 - distributed.worker - INFO -          dashboard at:          172.16.3.62:42460
2023-05-03 13:33:32,196 - distributed.worker - INFO - Waiting to connect to:    tcp://172.16.3.87:37981
2023-05-03 13:33:32,196 - distributed.worker - INFO - -------------------------------------------------
2023-05-03 13:33:32,196 - distributed.worker - INFO -               Threads:                         36
2023-05-03 13:33:32,196 - distributed.worker - INFO -                Memory:                 178.81 GiB
2023-05-03 13:33:32,196 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-9yftugiz
2023-05-03 13:33:32,196 - distributed.worker - INFO - -------------------------------------------------
2023-05-03 13:33:32,202 - distributed.worker - INFO -         Registered to:    tcp://172.16.3.87:37981
2023-05-03 13:33:32,202 - distributed.worker - INFO - -------------------------------------------------
2023-05-03 13:33:32,203 - distributed.core - INFO - Starting established connection to tcp://172.16.3.87:37981
/vortexfs1/home/anthony.meza/mambaforge/envs/atm_rivers/lib/python3.10/site-packages/scipy/io/_netcdf.py:305: RuntimeWarning: Cannot close a netcdf_file opened with mmap=True, when netcdf_variables or arrays referring to its data still exist. All data arrays obtained from such files refer directly to data on disk, and must be copied before the file can be cleanly closed. (See netcdf_file docstring for more information on mmap.)
  warnings.warn((
HDF5-DIAG: Error detected in HDF5 (1.14.0) thread 1:
  #000: H5D.c line 1390 in H5Dwrite(): can't synchronously write data
    major: Dataset
    minor: Write failed
  #001: H5D.c line 1333 in H5D__write_api_common(): can't write data
    major: Dataset
    minor: Write failed
  #002: H5VLcallback.c line 2282 in H5VL_dataset_write_direct(): dataset write failed
    major: Virtual Object Layer
    minor: Write failed
  #003: H5VLcallback.c line 2237 in H5VL__dataset_write(): dataset write failed
    major: Virtual Object Layer
    minor: Write failed
  #004: H5VLnative_dataset.c line 408 in H5VL__native_dataset_write(): can't write data
    major: Dataset
    minor: Write failed
  #005: H5Dio.c line 739 in H5D__write(): can't write data
    major: Dataset
    minor: Write failed
  #006: H5Dcontig.c line 921 in H5D__contig_write(): contiguous write failed
    major: Dataset
    minor: Write failed
  #007: H5Dselect.c line 493 in H5D__select_write(): write error
    major: Dataspace
    minor: Write failed
  #008: H5Dselect.c line 230 in H5D__select_io(): write error
    major: Dataspace
    minor: Write failed
  #009: H5Dcontig.c line 1530 in H5D__contig_writevv(): can't perform vectorized sieve buffer write
    major: Dataset
    minor: Can't operate on object
  #010: H5VM.c line 1400 in H5VM_opvv(): can't perform operation
    major: Internal error (too specific to document in detail)
    minor: Can't operate on object
  #011: H5Dcontig.c line 1283 in H5D__contig_writevv_sieve_cb(): block write failed
    major: Dataset
    minor: Write failed
  #012: H5Fio.c line 190 in H5F_shared_block_write(): write through page buffer failed
    major: Low-level I/O
    minor: Write failed
  #013: H5PB.c line 1017 in H5PB_write(): write through metadata accumulator failed
    major: Page Buffering
    minor: Write failed
  #014: H5Faccum.c line 832 in H5F__accum_write(): file write failed
    major: Low-level I/O
    minor: Write failed
  #015: H5FDint.c line 306 in H5FD_write(): driver write request failed
thread 2:

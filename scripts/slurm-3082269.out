2023-05-03 10:46:38,487 - distributed.nanny - INFO -         Start Nanny at: 'tcp://172.16.3.61:40580'
2023-05-03 10:46:40,552 - distributed.worker - INFO -       Start worker at:    tcp://172.16.3.61:40920
2023-05-03 10:46:40,552 - distributed.worker - INFO -          Listening to:    tcp://172.16.3.61:40920
2023-05-03 10:46:40,552 - distributed.worker - INFO -           Worker name:             SLURMCluster-0
2023-05-03 10:46:40,552 - distributed.worker - INFO -          dashboard at:          172.16.3.61:44384
2023-05-03 10:46:40,552 - distributed.worker - INFO - Waiting to connect to:   tcp://172.16.3.158:35777
2023-05-03 10:46:40,552 - distributed.worker - INFO - -------------------------------------------------
2023-05-03 10:46:40,552 - distributed.worker - INFO -               Threads:                         36
2023-05-03 10:46:40,552 - distributed.worker - INFO -                Memory:                 178.81 GiB
2023-05-03 10:46:40,552 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-cbu6z9zz
2023-05-03 10:46:40,552 - distributed.worker - INFO - -------------------------------------------------
2023-05-03 10:46:40,557 - distributed.worker - INFO -         Registered to:   tcp://172.16.3.158:35777
2023-05-03 10:46:40,557 - distributed.worker - INFO - -------------------------------------------------
2023-05-03 10:46:40,557 - distributed.core - INFO - Starting established connection to tcp://172.16.3.158:35777
2023-05-03 10:48:00,410 - distributed.utils_perf - INFO - full garbage collection released 3.03 GiB from 301 reference cycles (threshold: 9.54 MiB)
2023-05-03 10:48:54,305 - distributed.utils_perf - INFO - full garbage collection released 1.87 GiB from 519 reference cycles (threshold: 9.54 MiB)
2023-05-03 10:48:58,422 - distributed.utils_perf - INFO - full garbage collection released 580.00 MiB from 379 reference cycles (threshold: 9.54 MiB)
2023-05-03 10:49:39,151 - distributed.utils_perf - INFO - full garbage collection released 21.72 MiB from 100 reference cycles (threshold: 9.54 MiB)
slurmstepd: error: *** JOB 3082269 ON pn011 CANCELLED AT 2023-05-03T11:05:40 ***

2023-05-04 14:25:32,372 - distributed.nanny - INFO -         Start Nanny at: 'tcp://172.16.3.70:42012'
2023-05-04 14:25:41,391 - distributed.worker - INFO -       Start worker at:    tcp://172.16.3.70:38567
2023-05-04 14:25:41,391 - distributed.worker - INFO -          Listening to:    tcp://172.16.3.70:38567
2023-05-04 14:25:41,391 - distributed.worker - INFO -           Worker name:            SLURMCluster-15
2023-05-04 14:25:41,391 - distributed.worker - INFO -          dashboard at:          172.16.3.70:40776
2023-05-04 14:25:41,391 - distributed.worker - INFO - Waiting to connect to:   tcp://172.16.3.106:43862
2023-05-04 14:25:41,391 - distributed.worker - INFO - -------------------------------------------------
2023-05-04 14:25:41,391 - distributed.worker - INFO -               Threads:                         36
2023-05-04 14:25:41,391 - distributed.worker - INFO -                Memory:                 178.81 GiB
2023-05-04 14:25:41,392 - distributed.worker - INFO -       Local Directory: /tmp/dask-worker-space/worker-gkkvaat1
2023-05-04 14:25:41,392 - distributed.worker - INFO - -------------------------------------------------
2023-05-04 14:25:41,398 - distributed.worker - INFO -         Registered to:   tcp://172.16.3.106:43862
2023-05-04 14:25:41,398 - distributed.worker - INFO - -------------------------------------------------
2023-05-04 14:25:41,398 - distributed.core - INFO - Starting established connection to tcp://172.16.3.106:43862
2023-05-04 14:25:59,850 - distributed.utils_perf - INFO - full garbage collection released 844.04 MiB from 100 reference cycles (threshold: 9.54 MiB)
2023-05-04 14:26:03,500 - distributed.utils_perf - INFO - full garbage collection released 2.43 GiB from 160 reference cycles (threshold: 9.54 MiB)
2023-05-04 14:26:04,954 - distributed.utils_perf - INFO - full garbage collection released 1.83 GiB from 260 reference cycles (threshold: 9.54 MiB)
2023-05-04 14:26:07,810 - distributed.utils_perf - INFO - full garbage collection released 1.49 GiB from 539 reference cycles (threshold: 9.54 MiB)
2023-05-04 14:26:11,276 - distributed.utils_perf - INFO - full garbage collection released 204.82 MiB from 579 reference cycles (threshold: 9.54 MiB)
2023-05-04 14:26:15,572 - distributed.utils_perf - INFO - full garbage collection released 430.51 MiB from 339 reference cycles (threshold: 9.54 MiB)
2023-05-04 14:26:19,491 - distributed.utils_perf - INFO - full garbage collection released 1.74 GiB from 259 reference cycles (threshold: 9.54 MiB)
2023-05-04 14:26:31,964 - distributed.utils_perf - INFO - full garbage collection released 31.19 MiB from 552 reference cycles (threshold: 9.54 MiB)
2023-05-04 14:57:44,159 - distributed.core - INFO - Removing comms to tcp://172.16.3.103:41902
2023-05-04 14:57:44,241 - distributed.core - INFO - Removing comms to tcp://172.16.3.104:33022
2023-05-04 15:24:44,866 - distributed.core - INFO - Removing comms to tcp://172.16.3.185:41432
slurmstepd: error: *** JOB 3082968 ON pn020 CANCELLED AT 2023-05-04T16:25:43 DUE TO TIME LIMIT ***
